{"cells":[{"cell_type":"code","source":["# import necessaries libs\nfrom pyspark.sql.functions import col, lit, current_date, to_date, sha1, udf, when, month, year, concat\nfrom pyspark.sql.types     import StringType, DoubleType\nfrom uuid                  import uuid4\nimport requests\nimport subprocess\nimport json"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"981e7342-5ab1-4fd3-a775-23e433484831"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["## parameters\n# aws s3 parameters\n#access_key = dbutils.secrets.get(scope = \"aws\", key = \"aws-access-key\")\n#secret_key = dbutils.secrets.get(scope = \"aws\", key = \"aws-secret-key\")\n#encoded_secret_key = secret_key.replace(\"/\", \"%2F\")\naws_bucket_name = \"stonedatalake\"\nmount_name = \"stonedatalake\"\n\n# datalake paths\nlanding_path = lambda table: f\"dbfs:/mnt/{mount_name}/landing/{table}\"\nbronze_path = lambda table: f\"dbfs:/mnt/{mount_name}/bronze/{table}\"\nsilver_path = lambda table: f\"dbfs:/mnt/{mount_name}/silver/{table}\"\ngold_path = lambda table: f\"dbfs:/mnt/{mount_name}/gold/{table}\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a91e380c-159e-48f0-bc80-aef0b9f323c4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# mount s3 bucket\n#dbutils.fs.mount(f\"s3a://{access_key}:{encoded_secret_key}@{aws_bucket_name}\", f\"/mnt/{mount_name}\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7f17eb7-6e47-4ea6-b02a-39c6fc830d7e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#### Auxiliary functions ####\nclass Auxiliary_functions():\n    \"\"\"\n    Class responsible for auxiliary functions\n    \"\"\"\n    def __init__(self):\n        pass\n\n    def download_file(self, url, path):\n        r = requests.get(url, stream=True)\n        if r.status_code == requests.codes.OK:\n            with open(path, 'wb') as new_file:\n                    for part in r.iter_content(chunk_size=256):\n                        new_file.write(part)\n        else:\n            r.raise_for_status()\n\n    def execute(self, command): \n        process = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)\n        stdout, stderr = process.communicate()\n        stdout, stderr = stdout.decode('utf-8'), stderr.decode('utf-8')\n        return str(process.returncode), stdout, stderr\n\n    def sink_data_into_deltalake(self, df, path, fields_merge=False, partition_table=False, vacuum=7):\n        try:\n            dbutils.fs.ls(path)\n            \n            if fields_merge:\n                df.createOrReplaceTempView(\"upsert_delta\")\n                spark.sql(f\"\"\"\n                            MERGE INTO delta.`{path}` AS t \n                            USING upsert_delta AS s\n                            ON ({fields_merge})\n                            WHEN MATCHED THEN UPDATE SET *\n                            WHEN NOT MATCHED THEN INSERT *\n                            \"\"\")\n            else:\n                print('Need provide the fields for the merge operation')\n                \n        except:\n        # Write Data Frame\n            # This command should be executed in the first execution\n            if partition_table:\n                df.write.mode(\"overwrite\").format(\"delta\").partitionBy(partition_table).save(path)\n            else:\n                df.write.mode(\"overwrite\").format(\"delta\").save(path)\n\n            spark.sql(f\"\"\"ALTER TABLE delta.`{path}` SET TBLPROPERTIES ('delta.autoOptimize.optimizeWrite' = 'true',\n                                                                            'delta.logRetentionDuration' = 'interval {vacuum} days',\n                                                                            'delta.deletedFileRetentionDuration' = 'interval {vacuum} days')\"\"\")\n\n    def _parse_json_dataframe(self, json_list):\n        string_list = [json.dumps(i) for i in json_list]\n        rdd = sc.parallelize(string_list)\n        return spark.read.json(rdd)\n\n    def download_api_to_dataframe(self, url):\n        r = requests.get(url)\n        j = r.json()\n        return self._parse_json_dataframe(j)\n    \n    def create_hive_table(self, database, table, s_schema, path, partition_table=False):\n        spark.sql(f\"CREATE DATABASE IF NOT EXISTS {database}\")\n        if partition_table:\n            spark.sql(f\"\"\"\n                        CREATE TABLE IF NOT EXISTS {database}.{table}\n                        ({s_schema})\n                        USING DELTA\n                        PARTITIONED BY ({partition_table})\n                        LOCATION '{path}'\n                       \"\"\")\n        else:\n            spark.sql(f\"\"\"\n                        CREATE TABLE IF NOT EXISTS {database}.{table}\n                        ({s_schema})\n                        USING DELTA\n                        LOCATION '{path}'\n                       \"\"\")\n    \naf = Auxiliary_functions()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8df62257-d38a-44e0-b88e-2ddb87b73739"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#### Divida ativa data ####\nclass Divida_ativa():\n    \"\"\"\n    Class responsible for the active-debt pipeline\n    \"\"\"\n    def __init__(self):\n        self._table = \"divida-ativa\"\n        self._url_base = 'http://dadosabertos.pgfn.gov.br/'\n        self._zip_name = 'Dados_abertos_Nao_Previdenciario.zip'\n        self._url_download = self._url_base + self._zip_name\n        self._landing_path = landing_path(self._table)\n        self._bronze_path = bronze_path(self._table)\n        self._silver_path = silver_path(self._table)\n        self._gold_path = gold_path(self._table)\n    \n    def _clean_landing(self):\n        dbutils.fs.rm(self._landing_path, True)\n        dbutils.fs.mkdirs(self._landing_path)\n    \n    def _landing(self):\n        af.download_file(self._url_download, f\"/tmp/{self._zip_name}\")\n        \n        # if need it its possible investigate the return, output and error values\n        ret, out, err = af.execute(f\"unzip /tmp/{self._zip_name}\")\n        \n        list_of_csv = [i for i in dbutils.fs.ls(\"file:/databricks/driver/\") if \"arquivo_lai_SIDA\" in i.path]\n\n        for i in list_of_csv:\n            dbutils.fs.mv(i.path, f\"{self._landing_path}/{i.name}\")\n        \n        dbutils.fs.rm(f\"file:/tmp/{self._zip_name}\", True)\n        \n        print(\"Data has landing\")\n        \n    def _bronze_layer(self):\n        # reading raw data divida-ativa and sink in bronze layer (delta format)\n        # reading\n        df_divida_ativa_raw = spark.read.csv(self._landing_path, sep=\";\", header=True, encoding=\"ISO-8859-1\")\n        # hashing sensite data\n        df_divida_ativa_raw = df_divida_ativa_raw.withColumn('hash_NOME_DEVEDOR', sha1(col('NOME_DEVEDOR')))\n        # drop sensitive data\n        df_divida_ativa_raw = df_divida_ativa_raw.drop(col('CPF_CNPJ'))\\\n                                                 .drop(col('NOME_DEVEDOR'))\\\n                                                 .drop(col('NUMERO_INSCRICAO'))\n        # adding date_load\n        df_divida_ativa_raw = df_divida_ativa_raw.withColumn('date_load', current_date().cast(StringType()))\n        # sink\n        af.sink_data_into_deltalake(df_divida_ativa_raw,\n                                    self._bronze_path,\n                                    partition_table='date_load')\n        \n        print('Data has sank in Bronze layer')\n        \n    def _silver_layer(self):\n        ## data handling and sink to silver layer\n        # reading\n        df_divida_ativa_bronze = spark.read.format(\"delta\").load(self._bronze_path)\n        # cast correct data type\n        df_divida_ativa_bronze = df_divida_ativa_bronze.withColumn('VALOR_CONSOLIDADO', col('VALOR_CONSOLIDADO').cast(DoubleType()))\\\n                                                       .withColumn('DATA_INSCRICAO', to_date(col('DATA_INSCRICAO'), \"dd/MM/yyyy\"))\n\n        # drop NA\n        df_divida_ativa_bronze = df_divida_ativa_bronze.na.drop()\n        # get unique key and time key\n        time_key = (when(month(col('DATA_INSCRICAO')).between(1,3),\n                         to_date(concat(year(col('DATA_INSCRICAO')), lit('0101')), \"yyyyMMdd\"))\\\n                   .when(month(col('DATA_INSCRICAO')).between(4,6),\n                         to_date(concat(year(col('DATA_INSCRICAO')), lit('0401')), \"yyyyMMdd\"))\\\n                   .when(month(col('DATA_INSCRICAO')).between(7,9),\n                         to_date(concat(year(col('DATA_INSCRICAO')), lit('0701')), \"yyyyMMdd\"))\\\n                   .when(month(col('DATA_INSCRICAO')).between(10,12),\n                         to_date(concat(year(col('DATA_INSCRICAO')), lit('1001')), \"yyyyMMdd\")))\n        \n        df_divida_ativa_bronze = df_divida_ativa_bronze.withColumn('time_key', time_key)\\\n                                                       .withColumn('uuid_key', udf(lambda: str(uuid4()))())\n        # reorder columns\n        order_columns = df_divida_ativa_bronze.columns\n        step_order_columns.append(order_columns.pop(-1))\n        step_order_columns.append(order_columns.pop(-1))\n        order_columns = step_order_columns + step_order_columns\n        df_divida_ativa_bronze = df_divida_ativa_bronze.select(order_columns)     \n        # sink\n        af.sink_data_into_deltalake(df_divida_ativa_bronze,\n                                    self._silver_path,\n                                    partition_table='date_load')\n        \n        print('Data has sank in Silver layer')\n    \n    def _gold_layer(self):\n        ## If necessary, aggregations and joins can be made and placed in the gold layer\n        pass\n\n    def start_pipeline(self):\n        self._clean_landing()\n        self._landing()\n        \n        self._bronze_layer()\n        self._clean_landing()\n        \n        self._silver_layer()\n        \n        self._gold_layer()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"eda4e95e-6331-4100-b4bb-4e6f76e2e3c5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#### Banco Central do Brasil data ####\nclass BCB():\n    \"\"\"\n    Class responsible for the Banco Central do Brasil pipeline\n    \"\"\"\n    def __init__(self, serie, table):\n        self._serie = serie\n        self._table = table\n        self._url_download = f\"http://api.bcb.gov.br/dados/serie/bcdata.sgs.{self._serie}/dados?formato=json\"\n        self._landing_path = landing_path(self._table)\n        self._bronze_path = bronze_path(self._table)\n        self._silver_path = silver_path(self._table)\n        self._gold_path = gold_path(self._table)\n    \n    def _bronze_layer(self):\n        # reading raw data from api and sink in bronze layer (delta format)\n        # reading\n        df_serie_raw = af.download_api_to_dataframe(self._url_download)\n        # adding date_load\n        df_serie_raw = df_serie_raw.withColumn('date_load', current_date().cast(StringType()))\n        # sink\n        af.sink_data_into_deltalake(df_serie_raw,\n                                    self._bronze_path,\n                                    partition_table='date_load')\n        \n        print('Data has sank in Bronze layer')\n    \n    def _silver_layer(self):\n        ## data handling and sink to silver layer\n        df_serie_bronze = spark.read.format(\"delta\").load(self._bronze_path)\n        # cast correct data type\n        df_serie_bronze = df_serie_bronze.withColumn('valor', col('valor').cast(DoubleType()))\\\n                                         .withColumn('data', to_date(col('data'), \"dd/MM/yyyy\"))\n        # drop NA\n        df_serie_bronze = df_serie_bronze.na.drop()\n        # sink\n        af.sink_data_into_deltalake(df_serie_bronze,\n                                    self._silver_path,\n                                    partition_table='date_load')\n        \n        print('Data has sank in Silver layer')\n    \n    def _gold_layer(self):\n        ## If necessary, aggregations and joins can be made and placed in the gold layer\n        pass\n    \n    def start_pipeline(self):\n        self._bronze_layer()\n        \n        self._silver_layer()\n        \n        self._gold_layer()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"deac8e2d-fccf-4277-b855-85c68bf21f7e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["#### Pipeline processing ####"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"736f8d60-2b74-454a-87d5-d331b59fb163"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["da = Divida_ativa()\nda.start_pipeline()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"377987c6-5c98-4d43-83e1-4d2448751c7b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["ccc = BCB('21388', 'credit-condition-corporate')\nccc.start_pipeline()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d0bc8d86-8207-4618-94a3-672da7e27e23"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["ccm = BCB('21395', 'credit-condition-mortgage')\nccm.start_pipeline()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"28180a7a-191e-4f22-878e-5ab4610ec4ec"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#### Creating metastore ####"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64a84638-2d74-4e1d-a049-43075f504675"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# divida_ativa_silver\naf.create_hive_table('stone_silver',\n                  'divida_ativa',\n                  '''\n                  uuid_key string,\n                  time_key string,\n                  TIPO_PESSOA string,\n                  TIPO_DEVEDOR string,\n                  UF_UNIDADE_RESPONSAVEL string,\n                  UNIDADE_RESPONSAVEL string,\n                  TIPO_SITUACAO_INSCRICAO string,\n                  SITUACAO_INSCRICAO string,\n                  RECEITA_PRINCIPAL string,\n                  DATA_INSCRICAO date,\n                  INDICADOR_AJUIZADO string,\n                  VALOR_CONSOLIDADO double,\n                  hash_NOME_DEVEDOR\n                  date_load string\n                  ''',\n                  silver_path('divida-ativa'),\n                  'date_load'\n                 )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"892ffdc9-f3c2-4be0-82aa-ba9f7b6d75c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# credit_condition_corporate_silver\naf.create_hive_table('stone_silver',\n                  'credit_condition_corporate',\n                  '''\n                  data date,\n                  valor double,\n                  date_load string\n                  ''',\n                  silver_path('credit-condition-corporate'),\n                  'date_load'\n                 )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ca42c0d1-bd35-4bc9-ad92-844d966cc1d1"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["# credit_condition_mortgage_silver\naf.create_hive_table('stone_silver',\n                  'credit_condition_mortgage',\n                  '''\n                  data date,\n                  valor double,\n                  date_load string\n                  ''',\n                  silver_path('credit-condition-mortgage'),\n                  'date_load'\n                 )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a9437889-038f-41d7-8052-60ceb140b36c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["#### Selecting from databases with SQL like language ####"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b159db93-c711-4c42-9ce9-f4b28b15d858"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql(\"\"\"\nSELECT *\nFROM stone_silver.divida_ativa\nLIMIT 100\n\"\"\").display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a786030-90a4-424e-9ef2-10cf24c87366"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql(\"\"\"\nSELECT *\nFROM stone_silver.credit_condition_corporate\nLIMIT 100\n\"\"\").display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6cb3c62-cf91-4f60-9314-2b295aa8d5d2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql(\"\"\"\nSELECT *\nFROM stone_silver.credit_condition_mortgage\nLIMIT 100\n\"\"\").display()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7528726b-cd3d-4b7e-9479-499f4d8e6eb6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"api-data-wrangling-final","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":632643244532194}},"nbformat":4,"nbformat_minor":0}
